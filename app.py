# --------------------------------------------------------------------------
# --- app.py (–í–µ—Ä—Å–∏—è 4.0: HyDE + –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ + –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ) ---
# --- –≠—Ç–æ —Å–∞–º–∞—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –≤–µ—Ä—Å–∏—è –Ω–∞—à–µ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞ ---
# --------------------------------------------------------------------------

import streamlit as st
import faiss
import json
import numpy as np
import google.generativeai as genai
from sentence_transformers import SentenceTransformer, CrossEncoder

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
FAISS_INDEX_PATH = "document_index.faiss"
CHUNK_DATA_PATH = "chunk_data.json"
BI_ENCODER_MODEL = 'all-MiniLM-L6-v2'
CROSS_ENCODER_MODEL = 'cross-encoder/ms-marco-MiniLM-L-6-v2'

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø GEMINI ---
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    gemini_model = genai.GenerativeModel('gemini-1.5-flash')
    GEMINI_AVAILABLE = True
except Exception as e:
    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Gemini API. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à —Å–µ–∫—Ä–µ—Ç–Ω—ã–π –∫–ª—é—á –≤ —Ñ–∞–π–ª–µ .streamlit/secrets.toml. –û—à–∏–±–∫–∞: {e}")
    GEMINI_AVAILABLE = False

# --- –ó–ê–ì–†–£–ó–ö–ê –†–ï–°–£–†–°–û–í ---
@st.cache_resource
def load_resources():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã: –º–æ–¥–µ–ª–∏, –∏–Ω–¥–µ–∫—Å –∏ –¥–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–æ–≤."""
    print("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞...")
    bi_encoder = SentenceTransformer(BI_ENCODER_MODEL)
    cross_encoder = CrossEncoder(CROSS_ENCODER_MODEL)
    index = faiss.read_index(FAISS_INDEX_PATH)
    with open(CHUNK_DATA_PATH, "r", encoding="utf-8") as f:
        chunks_data = json.load(f)
    print("–†–µ—Å—É—Ä—Å—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
    return bi_encoder, cross_encoder, index, chunks_data

bi_encoder, cross_encoder, index, chunks_data = load_resources()

# --- –§–£–ù–ö–¶–ò–ò –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ---

def generate_hypothetical_answer(query):
    """
    ‚úÖ –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø (HyDE): –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞.
    """
    if not GEMINI_AVAILABLE:
        st.warning("Gemini –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–∏—Å–∫ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É.")
        return query
    
    try:
        # –ü—Ä–æ–º–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ—Å–∏—Ç –º–æ–¥–µ–ª—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–¥–µ–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
        prompt = f"""
        –ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —Ç—ã —é—Ä–∏—Å—Ç-—ç–∫—Å–ø–µ—Ä—Ç. –í –æ—Ç–≤–µ—Ç –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –Ω–∞–ø–∏—à–∏ –æ–¥–∏–Ω –∫–æ—Ä–æ—Ç–∫–∏–π, 
        –∏–¥–µ–∞–ª—å–Ω—ã–π –∞–±–∑–∞—Ü, –∫–æ—Ç–æ—Ä—ã–π –º–æ–≥ –±—ã —Å–æ–¥–µ—Ä–∂–∞—Ç—å—Å—è –≤ –º–æ—Ç–∏–≤–∏—Ä–æ–≤–æ—á–Ω–æ–π —á–∞—Å—Ç–∏ —Å—É–¥–µ–±–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è –∏ 
        –∫–æ—Ç–æ—Ä—ã–π –±—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–≤–µ—á–∞–ª –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å. –ê–±–∑–∞—Ü –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞—Å—ã—â–µ–Ω–Ω—ã–º –∏ –ø–æ –¥–µ–ª—É. 
        –ù–µ –ø–∏—à–∏ –Ω–∏—á–µ–≥–æ, –∫—Ä–æ–º–µ —ç—Ç–æ–≥–æ –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–±–∑–∞—Ü–∞.

        –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{query}"
        """
        response = gemini_model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–≤–µ—Ç. –ü–æ–∏—Å–∫ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É. –û—à–∏–±–∫–∞: {e}")
        return query


def search(search_text, k=30):
    """–ü–µ—Ä–≤–∏—á–Ω—ã–π –ø–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ FAISS –ø–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É."""
    query_vector = bi_encoder.encode([search_text], normalize_embeddings=True)
    query_vector_np = np.array(query_vector).astype('float32')
    distances, indices = index.search(query_vector_np, k)
    
    unique_parent_texts = set()
    results = []
    for i in indices[0]:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–Ω–¥–µ–∫—Å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –¥–∞–Ω–Ω—ã—Ö
        if i < len(chunks_data):
            parent_text = chunks_data[i]['parent_text']
            if parent_text not in unique_parent_texts:
                results.append(chunks_data[i])
                unique_parent_texts.add(parent_text)
    return results

def rerank(original_query, search_results, top_k=5):
    """–ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é Cross-Encoder –ø–æ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ú–£ –∑–∞–ø—Ä–æ—Å—É."""
    if not search_results:
        return []
    # –í–∞–∂–Ω–æ: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å —Ñ–æ–∫—É—Å
    pairs = [[original_query, result['parent_text']] for result in search_results]
    scores = cross_encoder.predict(pairs, show_progress_bar=False)
    
    for i in range(len(scores)):
        search_results[i]['rerank_score'] = scores[i]
        
    reranked_results = sorted(search_results, key=lambda x: x['rerank_score'], reverse=True)
    return reranked_results[:top_k]

# --- –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –ò–ù–¢–ï–†–§–ï–ô–° ---

st.title("‚öñÔ∏è –î–µ–º–æ 4.0: –ü–æ–∏—Å–∫ —Å –ø–æ–º–æ—â—å—é HyDE")
st.write("–¢–µ–ø–µ—Ä—å —Å–∏—Å—Ç–µ–º–∞ —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ—Å–∏—Ç Gemini –Ω–∞–ø–∏—Å–∞—Ç—å '–∏–¥–µ–∞–ª—å–Ω—ã–π' –æ—Ç–≤–µ—Ç –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å, –∞ –∑–∞—Ç–µ–º –∏—â–µ—Ç –≤ –±–∞–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ —ç—Ç–æ—Ç –∏–¥–µ–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç.")

user_query = st.text_input("–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:", "—É–¥–æ—Ä–æ–∂–∞–Ω–∏–µ –¥–æ–≥–æ–≤–æ—Ä–∞")

if st.button("–ù–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç"):
    if user_query:
        # –≠—Ç–∞–ø 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (HyDE)
        with st.spinner("–≠—Ç–∞–ø 1: –ü—Ä–æ—à—É Gemini –ø–æ–º–æ—á—å —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∏–¥–µ–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç..."):
            hypothetical_answer = generate_hypothetical_answer(user_query)
        
        st.info(f"**–ì–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–≤–µ—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞:**\n\n{hypothetical_answer}")

        # –≠—Ç–∞–ø 2: –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–æ–º—É –æ—Ç–≤–µ—Ç—É
        with st.spinner("–≠—Ç–∞–ø 2: –ò—â—É –¥–æ–∫—É–º–µ–Ω—Ç—ã, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ '–∏–¥–µ–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç'..."):
            initial_results = search(hypothetical_answer)

        if initial_results:
            # –≠—Ç–∞–ø 3: –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É
            with st.spinner("–≠—Ç–∞–ø 3: '–≠–∫—Å–ø–µ—Ä—Ç' –≤—ã–±–∏—Ä–∞–µ—Ç 5 –ª—É—á—à–∏—Ö, —Å–≤–µ—Ä—è—è—Å—å —Å –≤–∞—à–∏–º –∏—Å—Ö–æ–¥–Ω—ã–º –≤–æ–ø—Ä–æ—Å–æ–º..."):
                final_results = rerank(user_query, initial_results)

            st.subheader("üèÜ –ì–ª–∞–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–ø–æ—Å–ª–µ –≤—Å–µ—Ö —É–ª—É—á—à–µ–Ω–∏–π):")
            if final_results:
                for i, result in enumerate(final_results):
                    st.markdown(f"---")
                    st.write(f"**–†–µ–∑—É–ª—å—Ç–∞—Ç #{i+1} (–∏–∑ —Ñ–∞–π–ª–∞: `{result['doc_name']}`)**")
                    st.info(f"**–û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏:** {result['rerank_score']:.2f}")
                    st.success(result['parent_text'])
            else:
                 st.error("–ü–æ—Å–ª–µ –≤—Å–µ—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
        else:
            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É.")
    else:
        st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å.")